Metadata-Version: 2.1
Name: ezic
Version: 0.1.0
Summary: 
Author: int
Requires-Python: >=3.10,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: anthropic (==0.54.0)
Requires-Dist: jedi (==0.18.0)
Requires-Dist: openai (>=1.51.2,<2.0.0)
Requires-Dist: parso (==0.8.0)
Requires-Dist: pydantic (>=2.8.0,<3.0.0)
Requires-Dist: pydantic-xml (>=2.11.0,<3.0.0)
Requires-Dist: python-dotenv (>=1.0.0,<2.0.0)
Requires-Dist: rich (>=13.7.1,<14.0.0)
Requires-Dist: structlog (>=24.2.0,<25.0.0)
Description-Content-Type: text/markdown

fork of https://github.com/protectai/vulnhuntr
just follow the setup here https://github.com/protectai/vulnhuntr if ya want (preferably)

just modify in the .env file on whatever LLM ya wanna do this with using ollama
btw the retry functionality has 20 tries so modify it if ya want (max_retries var in main.py)
it usually dies after like 3 files though from my experience using llama3.2, largely due to the model itself, not really the prompts prob, i think
rn, ive got it to work with llama3.2 (ollama) (not really, just added retry functionality with some prompt engineering and hoped for the best)
